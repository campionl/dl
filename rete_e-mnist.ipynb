{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C81Q3ZLjwy8"
   },
   "source": [
    "Iniziamo la creazione della rete importando tutte le librerie che ci occorrono per creare il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gcj2UTsg8V_Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOBWbLqijsNT"
   },
   "source": [
    "Carichiamo il dataset emnist e sistemiamo le immagini siccome il dataset le importa girate di 90 gradi e specchiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ca4a25cf6d4a4f2a831f2d9975454df1",
      "11f6797d47e54f3c8540c2871932e6cc",
      "d2e22e38743e4c56a866f0255a6e28f4",
      "217cfd40a2664d05b8fc12cdfd0b41c1",
      "47f3c9e78d334304afc3d4881cf40cb7",
      "ba95069dd1984cbe84c0da52db2d5a2c",
      "5428b3859e3a40a2870460c7aec8f0a9",
      "8794f72c4eb74f98b216c31616dcfc62",
      "8b70d75e4f9742b19c73e17eaa58fa2c",
      "2c286d95d1724a7cba5453d892917394",
      "efbc75e07da44ab6a2fbf66572dcffc1",
      "30ce059027ab471a839ad868504a9342",
      "b4375b89e32b4bbd8a8d2274c781b140",
      "adee985be8b94861991bee017a362519",
      "10d44b7a159f4b3098236387c2d16ffb",
      "bcf81d0e1d1e4dc5a736de14f0d3b00b",
      "2926715cfc414adc8d3251000f463514",
      "84850e38d4f24d37ad5f5034391207c7",
      "2ee16c717a0d4eb188286d50bd0babeb",
      "2cd1172c62d54b81931f3ca79aab2b82",
      "8a2aea22a2a04f4f85c5203d3d22dc90",
      "dad3e8f7f38344369fa1be9c53701750",
      "4885c1fea330441490f0f34e73e01eb3",
      "32982a1145ed46999c45ddde0a98cd48",
      "abd6e4394d754ded83071f7c0ae24bfd",
      "02f3239e165648a687946f52cde76086",
      "65ff19825a1c4e9e86f2696b547648f1",
      "e9600713c8374cbfbd902825280cef94",
      "bfe72d4ef5bf4426955788bdcac22ae8",
      "e2be5a06923c457ba7cc1fa2fec044de",
      "be0c94d888a346e0914c47c000049c91",
      "1c7fd6ebbf45418289f9fe56028d6fe1",
      "6bf811b0efbf492fa89ade971bc69518",
      "31a4f34b4b7e4978a3f6bce25a5c2dba",
      "c3dfd06ed7b64a889d4f62ce47dc970d",
      "11cad0ffadea45f59c67b76ea2126a55",
      "7d9ffcde93b446a58dd98afc0ea1ed59",
      "c59a3af767fe445b8247eb0bba4937e3",
      "2bfd16a3cdd34f72ac010e75828fff43",
      "fcbe48b329dc48aea03be785b1fc9085",
      "2634e3575ac04521bfc609167a7c3e99",
      "c16363b14b054c1e9b4551979fa390b6",
      "e8e224c2f76d446ca6fd17b59eedb89f",
      "46986234815a40b3b886c5600f337e84",
      "7f3872f8200e4a75aaec773c403a914c",
      "ba04ac8560b84a3aa96ba80daa626ac6",
      "201c75d80b6848f1a53a3b605c3fb424",
      "8d1bc796acd744ddaa3d7d82f266c23b",
      "527de3bca0274e0ebf2cda8b6de77617",
      "85262972173f43fe9186cdf935fdaef9",
      "916ec925e1d342bbb37cf1951ad6b2eb",
      "6def574cc7aa42a9968125f26d673c4b",
      "0897e9306e54420c896551da4640ed7e",
      "2ebf7d2a5fa64ae9a416cf100b4a761a",
      "b74cd2b2b1b74ff8819eb22a7dd9d5c4",
      "287bfb83c4d94253850de2fd180639c8",
      "7ec421d1807145c08d24f53d87affc9c",
      "78310fc1960f45318bee3c26c3e2320b",
      "55c258b1c3bd4e2ea44d828fa0df99ef",
      "8a937881308e49c8983de026d05452f2",
      "a43734274d6a4ab59bafc12d6eaf5b0a",
      "5312571c26114e5c970d1cbcb6a0e0bf",
      "83e7aebabdd446ca83eeb3662c3987c5",
      "0b3dc2c38b3848d19b5225cdd50fbc73",
      "688a81e8a38342139db22ac3796bbfe8",
      "cf086dfe77bb4221bdcb6c3bd03ab911",
      "d3574419828d48d8b9c6d121aed26f69",
      "4b32abf5a0394e869671896f3c8817ea",
      "ad58b6f587da494c816691d4cd7dd350",
      "fbdbdf6c6d1347e9ac5619cb21053161",
      "3c776e19767f498cbd3f906bb5167f3a",
      "6d3955c84dd143fb98a3d262a0c98bc4",
      "cc172b5ef0504941b71a94af1d18fd62",
      "35bcd5614d2740f3a7940940c91785b4",
      "f47f4fa989124a119816dc64a3093416",
      "400c27096abf44e0a811dc3db00fc8f5",
      "9cacf95a171648da94d9fc193174e2f4",
      "9aa3a34ce24f46fcad478f4eaf2c9d08",
      "5caa2111e7c2432f87f9a4f45b512709",
      "e0baa6d3aafb4776969df8d4a8b819e3",
      "4ef35c1108db414e91ccc6f8a773b740",
      "007c4ee37b7f4e4c9874cf8d9504125e",
      "bc20560a7522467fb6afbd5e831356d0",
      "be5c29604309482784a1f0196c3a86eb",
      "6ec0f4e1617e44538067f431b8e2daef",
      "d21fdf6c8ac0498aa9176d9209aa51e5",
      "a64a37af412949fc85199d139da768fb",
      "d50945ff26be4c6db194711612c90ce1",
      "4f5bb726f6c346e4aa2d222ad9e435ea",
      "331fe47254654004af9d9acc9b48ecac",
      "21b8aae5dd4543c7a8ce7626e0309a22",
      "75009c2095ee4179820c102d666afd1d",
      "85ad55fb842a4d41be1cc7dafe81a648",
      "177a126fbb2c4d97aae6b1bf5e939df1",
      "973b21eb174d4c448652959c171d83a6",
      "9581671ce2c74de2beb6242cf18ec591",
      "7831a5cba2ae4490bca05ae974d41f9e",
      "c0fbb44c20af47159e8d867d565d1a05",
      "4de8dce9b3954ac6ac26bacaad6e3d8c"
     ]
    },
    "id": "-QvZprKDS4F0",
    "outputId": "1073ffea-b1be-4a81-e53c-ec84e90f9f45"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.rot90(image, k=-1)\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    label -= 1\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "ds_train = ds_train.map(preprocess).shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for images, labels in ds_train.take(1):\n",
    "    for i in range(5):\n",
    "        plt.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
    "        plt.title(f\"Lettera: {chr(int(labels[i]) + 65)}\")  # 0='A'\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL6yBcwUkxTn"
   },
   "source": [
    "Ora definiamo la struttura del modello:\n",
    "Creiamo un conv2d per estrarre i dati importanti(controni, bordi, etc...), col max pooling estraiamo il dato più significativo in una matrice 2x2 ed infine col dropout evitiamo l'overfitting.\n",
    "\n",
    "Lo ripetiamo un'altra volta.\n",
    "\n",
    "Usiamo flatten per appiattire l'immagine prima del dense in modo che il modello la possa leggere.\n",
    "Elaboriamo le info col dense, ultimo dropout ed infine in output mettiamo soft max siccome abbiamo un output classificabile con 26 neuroni siccome le lettere sono 26.\n",
    "\n",
    "Poi assegnamo al modello le direttive come optimizer, loss (che sarà sparse_categorical_crossentropy, funzione di perdita utilizzata in problemi di classificazione multi-classe, dove le etichette target sono rappresentate come interi, ovvero gli indici delle classi, invece di vettori one-hot).\n",
    "\n",
    "Infine definiamo l'allenamento per l'IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkZwRKEByj_o",
    "outputId": "699dba6b-9c6a-49f5-89d1-8c1cc075981f"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (2, 2), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(64, (2, 2), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=13,\n",
    "                    validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "n0RuN55UtrNY",
    "outputId": "12a47a65-aafb-4c21-a180-11113c00419e"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.title('Accuratezza durante l\\'allenamento')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wk0hGUMZUYFJ",
    "outputId": "3a636ea8-0d60-4005-9259-40f0dd627f24"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from google.colab import output\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "canvas_html = \"\"\"\n",
    "<canvas id=\"canvas\" width=\"280\" height=\"280\" style=\"border:1px solid black;\"></canvas>\n",
    "<br>\n",
    "<button onclick=\"predict()\">Predict</button>\n",
    "<button onclick=\"clearCanvas()\">Clear</button>\n",
    "\n",
    "<script>\n",
    "let canvas = document.getElementById('canvas');\n",
    "let ctx = canvas.getContext('2d');\n",
    "let drawing = false;\n",
    "\n",
    "canvas.addEventListener('mousedown', () => { drawing = true; });\n",
    "canvas.addEventListener('mouseup', () => { drawing = false; ctx.beginPath(); });\n",
    "canvas.addEventListener('mouseout', () => { drawing = false; ctx.beginPath(); });\n",
    "\n",
    "canvas.addEventListener('mousemove', (event) => {\n",
    "  if (!drawing) return;\n",
    "  ctx.lineWidth = 20;\n",
    "  ctx.lineCap = \"round\";\n",
    "  ctx.strokeStyle = \"white\";\n",
    "  ctx.lineTo(event.offsetX, event.offsetY);\n",
    "  ctx.stroke();\n",
    "  ctx.beginPath();\n",
    "  ctx.moveTo(event.offsetX, event.offsetY);\n",
    "});\n",
    "\n",
    "ctx.fillStyle = \"black\";\n",
    "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "\n",
    "function clearCanvas() {\n",
    "  ctx.fillStyle = \"black\";\n",
    "  ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "}\n",
    "\n",
    "function predict() {\n",
    "  const dataURL = canvas.toDataURL();\n",
    "  google.colab.kernel.invokeFunction('notebook.predict_digit', [dataURL], {});\n",
    "}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(canvas_html))\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = img.convert('L') # Convert to grayscale\n",
    "    # The image from the canvas is already 280x280, resize it directly\n",
    "    img = img.resize((28, 28))\n",
    "\n",
    "    # Optional: display the resized image for verification\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Immagine ridimensionata')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    img_array = np.expand_dims(img_array, -1) # Add channel dimension\n",
    "    return np.expand_dims(img_array, 0) # Add batch dimension\n",
    "\n",
    "def predict_digit(data):\n",
    "    data = data.split(',')[1]\n",
    "    binary = base64.b64decode(data)\n",
    "    img = Image.open(io.BytesIO(binary))\n",
    "    processed_img = preprocess_image(img)\n",
    "    prediction = model.predict(processed_img)[0]\n",
    "    pred_class = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    pred_letter = chr(pred_class + 65)\n",
    "    display(HTML(f\"<h3>Predicted: {pred_letter} (Confidence: {confidence:.2%})</h3>\"))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(range(26), prediction)\n",
    "    plt.xticks(range(26), [chr(i + 65) for i in range(26)])\n",
    "    plt.title('Prediction Probabilities for Each Letter (A-Z)')\n",
    "    plt.show()\n",
    "\n",
    "output.register_callback('notebook.predict_digit', predict_digit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-Sp6vQonCgm"
   },
   "source": [
    "Con questo blocco possiamo visualizzare i pesi del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "tXUH3X8TVUWZ",
    "outputId": "1f0beb73-dd18-4f6c-eb9b-c27228657b3c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prendi i pesi del primo layer conv2D\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "# filters shape: (height, width, input_channels, num_filters)\n",
    "num_filters = filters.shape[3]\n",
    "\n",
    "fig, axes = plt.subplots(1, num_filters, figsize=(20,5))\n",
    "for i in range(num_filters):\n",
    "    f = filters[:, :, 0, i]  # prendi il filtro relativo al primo canale input\n",
    "    axes[i].imshow(f, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkdQs1J3nM9G"
   },
   "source": [
    "Con questo blocco invece li possiamo salvare da colab in locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "rIal7-RxWH7D",
    "outputId": "b94d6074-b3db-4a9f-b6f0-cb36ab3547d1"
   },
   "outputs": [],
   "source": [
    "model.save_weights('modello_pesi.weights.h5')\n",
    "\n",
    "from google.colab import files\n",
    "files.download('modello_pesi.weights.h5')\n",
    "\n",
    "model.save('modello_completo.h5')  # Salva struttura + pesi\n",
    "files.download('modello_completo.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
